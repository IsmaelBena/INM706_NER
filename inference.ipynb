{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from dataset import LocalDataset, NERDataset\n",
    "from baseline_lstm import LSTM_Model\n",
    "from bidirectional_lstm import BiLSTM_Model\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Device: {device}')\n",
    "\n",
    "checkpoint_dir = os.path.join(os.getcwd(), \"checkpoints\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local csv from: e:\\Uni\\MSc AI\\INM706-Sequential-Analysis\\INM706_NER\\dataset\n"
     ]
    }
   ],
   "source": [
    "local_raw_dataset = LocalDataset('dataset')\n",
    "local_raw_dataset.loadDataset()\n",
    "local_data_dict = local_raw_dataset.prepareDataset()\n",
    "\n",
    "label_ids = local_data_dict[\"label_ids\"]\n",
    "vocab = local_data_dict[\"vocab\"]\n",
    "tags = list(label_ids.keys())\n",
    "test_dataset = NERDataset((local_data_dict[\"test_sentences\"], local_data_dict[\"test_labels\"]))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104])\n",
      "torch.Size([104])\n"
     ]
    }
   ],
   "source": [
    "# Get the first sentence and labels in the test dataset\n",
    "\n",
    "for sentences, labels in test_dataloader:\n",
    "    sentence = sentences[20]\n",
    "    label = labels[20]\n",
    "    break\n",
    "\n",
    "print(sentence.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentence:\n",
      "comes O\n",
      "operations O\n",
      "place O\n",
      "sidelines O\n",
      "Iraq O\n",
      "Venevision O\n",
      "Bekasi O\n",
      "Iraq O\n",
      "war O\n",
      "Pakhtunkhwa O\n",
      "lands O\n",
      "quotes O\n",
      "including O\n",
      "IAEA O\n",
      "His O\n",
      "bulk O\n",
      "correctness O\n",
      "Helicopter O\n",
      "marched O\n",
      "4.6 O\n",
      "government O\n",
      "eve O\n",
      "buses O\n",
      "Ethiopian-born O\n",
      "shortage O\n",
      "Militant O\n",
      "backing B-geo\n",
      "demand O\n",
      "aircraft B-org\n",
      "from O\n",
      "Iraq O\n",
      "man B-geo\n",
      "Families O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Uni\\MSc AI\\INM706-Sequential-Analysis\\INM706_NER\\INM706_cw_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    }
   ],
   "source": [
    "# get base lstm model and run it\n",
    "\n",
    "with open(f'{checkpoint_dir}\\\\LSTM_500ep.pkl', 'rb') as file:\n",
    "    baseline_lstm_model = pickle.load(file)\n",
    "\n",
    "\n",
    "lstm_input = torch.tensor(np.array([sentence]), device=device)\n",
    "baseline_lstm_model.eval()\n",
    "label_pred_scores = baseline_lstm_model(lstm_input)\n",
    "tag_preds = torch.argmax(label_pred_scores, dim=2)\n",
    "\n",
    "np_tags = tag_preds[0].cpu().numpy()\n",
    "\n",
    "print('Output sentence:')\n",
    "for ind, word in enumerate(sentence.numpy()):\n",
    "    if word > 0:\n",
    "        print(vocab[word], tags[np_tags[ind]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sentence:\n",
      "faith O\n",
      "restarted O\n",
      "including O\n",
      "backing B-geo\n",
      "explained O\n",
      "kidnapped O\n",
      "bilateral O\n",
      "being O\n",
      "expect O\n",
      "mutate O\n",
      "energy O\n",
      "protest O\n",
      "running O\n",
      "participate O\n",
      "Iraq O\n",
      "war O\n",
      "city O\n",
      "Mosul O\n",
      "demonstrators O\n",
      "offensive B-geo\n",
      "recognition O\n",
      "war O\n",
      "Soh B-geo\n",
      "extension O\n",
      "including O\n",
      "finds O\n",
      "military B-gpe\n",
      "blame O\n",
      "Juba O\n",
      "Anbar O\n",
      "protest O\n",
      "inside O\n",
      "Families O\n"
     ]
    }
   ],
   "source": [
    "# get bidirectional lstm model and run it\n",
    "\n",
    "with open(f'{checkpoint_dir}\\\\biLSTM_500ep.pkl', 'rb') as file:\n",
    "    bi_lstm_model = pickle.load(file)\n",
    "\n",
    "\n",
    "bilstm_input = torch.tensor(np.array([sentence]), device=device)\n",
    "bi_lstm_model.eval()\n",
    "label_pred_scores = bi_lstm_model(bilstm_input)\n",
    "tag_preds = torch.argmax(label_pred_scores, dim=2)\n",
    "\n",
    "np_tags = tag_preds[0].cpu().numpy()\n",
    "\n",
    "print('Output sentence:')\n",
    "for ind, word in enumerate(sentence.numpy()):\n",
    "    if word > 0:\n",
    "        print(vocab[word], tags[np_tags[ind]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INM706_cw_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
